{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Train Hate Speech Classification Neural Network Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "With the data cleaned and processed, this notebook implements model training on the data sets. The code in this notebook assumes that cleaned data is in the filepath `\"data/combined_deduped.csv\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_fscore_support, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from tensorflow import keras\n",
    "from wandb.keras import WandbCallback\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Neural Network Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The \"baseline\" implementation of a neural network is more debatable. Our choice was to set up a simple multilayer perceptron with enough neurons and layers to be functional and little customization beyond that. \n",
    "\n",
    "First, we instantiate a CountVectorizer to transform the words into integer counts of word appearance. Next, we scale that data and convert it from sparse matrices to arrays. Finally, we create, compile, and fit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words = 'english', max_features=3000)\n",
    "x_train_vect = vect.fit_transform(x_train)\n",
    "x_val_vect = vect.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean = False)\n",
    "x_train_vect_scale = scaler.fit_transform(x_train_vect)\n",
    "x_val_vect_scale = scaler.transform(x_val_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x_train_vect_scale = x_train_vect_scale.toarray()\n",
    "x_val_vect_scale = x_val_vect_scale.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, input_dim=3000, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23/runs/1s3qjow5\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23/runs/1s3qjow5</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99459 samples\n",
      "Epoch 1/5\n",
      "99459/99459 [==============================] - 37s 376us/sample - loss: 0.6787 - accuracy: 0.8567\n",
      "Epoch 2/5\n",
      "99459/99459 [==============================] - 24s 239us/sample - loss: 0.2212 - accuracy: 0.9178\n",
      "Epoch 3/5\n",
      "99459/99459 [==============================] - 23s 231us/sample - loss: 0.1629 - accuracy: 0.9403\n",
      "Epoch 4/5\n",
      "99459/99459 [==============================] - 23s 227us/sample - loss: 0.1284 - accuracy: 0.9523\n",
      "Epoch 5/5\n",
      "99459/99459 [==============================] - 22s 216us/sample - loss: 0.1105 - accuracy: 0.9586\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"allay-ds-23\")\n",
    "\n",
    "results = model.fit(x_train_vect_scale,\n",
    "                    y_train,\n",
    "                    epochs=5,\n",
    "                   batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17552/17552 [==============================] - 7s 419us/sample - loss: 0.7213 - accuracy: 0.8445\n",
      "17552/17552 [==============================] - 3s 188us/sample\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_val_vect_scale, y_val)\n",
    "y_pred = model.predict(x_val_vect_scale, batch_size=64, verbose=1)\n",
    "y_pred = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False     0.8485    0.8924    0.8699     10223\n",
      "        True     0.8382    0.7777    0.8069      7329\n",
      "\n",
      "    accuracy                         0.8445     17552\n",
      "   macro avg     0.8434    0.8351    0.8384     17552\n",
      "weighted avg     0.8442    0.8445    0.8436     17552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1 = .8445, .8382, .7777, .8069\n",
    "\n",
    "wandb.log({'accuracy':accuracy, 'recall':recall, \n",
    "               'f1':f1, 'precision':precision})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Next we try the same thing, but with a Tf-Idf vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words = 'english', max_features=3000)\n",
    "x_train_vect = vect.fit_transform(x_train)\n",
    "x_val_vect = vect.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x_train_vect = x_train_vect.toarray()\n",
    "x_val_vect = x_val_vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, input_dim=3000, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23/runs/rdo8hvke\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23/runs/rdo8hvke</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99459 samples\n",
      "Epoch 1/5\n",
      "99459/99459 [==============================] - 25s 253us/sample - loss: 0.3500 - accuracy: 0.8495\n",
      "Epoch 2/5\n",
      "99459/99459 [==============================] - 31s 307us/sample - loss: 0.3024 - accuracy: 0.8731\n",
      "Epoch 3/5\n",
      "99459/99459 [==============================] - 20s 206us/sample - loss: 0.2700 - accuracy: 0.8885\n",
      "Epoch 4/5\n",
      "99459/99459 [==============================] - 20s 204us/sample - loss: 0.2257 - accuracy: 0.9090\n",
      "Epoch 5/5\n",
      "99459/99459 [==============================] - 20s 203us/sample - loss: 0.1735 - accuracy: 0.9319\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"allay-ds-23\")\n",
    "results = model.fit(x_train_vect,\n",
    "                    y_train,\n",
    "                    epochs=5,\n",
    "                   batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17552/17552 [==============================] - 1s 54us/sample\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False     0.8541    0.9035    0.8781     10223\n",
      "        True     0.8535    0.7847    0.8177      7329\n",
      "\n",
      "    accuracy                         0.8539     17552\n",
      "   macro avg     0.8538    0.8441    0.8479     17552\n",
      "weighted avg     0.8538    0.8539    0.8528     17552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val_vect, batch_size=64, verbose=1)\n",
    "y_pred = np.round(y_pred)\n",
    "print(classification_report(y_val, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "accuracy, precision, recall, f1 = .8539, .8535, .7847, .8177\n",
    "\n",
    "wandb.log({'accuracy':accuracy, 'recall':recall, \n",
    "               'f1':f1, 'precision':precision})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## RNN + LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The next model we try is a recurrent neural network with LSTM. This relies on having pickled lemmatized data in the filepath `data/lemmas_2020-05-04-16-27-18Z.pkl.xz`. See other notebook for lemmatization methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "lemmas = pd.read_pickle(\"data/lemmas_2020-05-04-16-27-18Z.pkl.xz\", compression = 'xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sm_lemmas</th>\n",
       "      <th>md_lemmas</th>\n",
       "      <th>lg_lemmas</th>\n",
       "      <th>inappropriate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[beat, Dr., Dre, urbeat, Wired, Ear, Headphone...</td>\n",
       "      <td>[beat, Dr., Dre, urbeat, Wired, ear, Headphone...</td>\n",
       "      <td>[beat, Dr., Dre, urBeats, wire, Ear, Headphone...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[@Papapishu, man, fucking, rule, party, perpet...</td>\n",
       "      <td>[@Papapishu, man, fucking, rule, party, perpet...</td>\n",
       "      <td>[@Papapishu, man, fucking, rule, party, perpet...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[time, draw, close, 128591;&amp;#127995, Father, d...</td>\n",
       "      <td>[time, draw, close, 128591;&amp;#127995, Father, d...</td>\n",
       "      <td>[time, draw, close, 128591;&amp;#127995, Father, d...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[notice, start, act, different, distant, peep,...</td>\n",
       "      <td>[notice, start, act, different, distant, peep,...</td>\n",
       "      <td>[notice, start, act, different, distant, peep,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[forget, unfollower, believe, grow, new, follo...</td>\n",
       "      <td>[forget, unfollower, believe, grow, new, follo...</td>\n",
       "      <td>[forget, unfollower, believe, grow, new, follo...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sm_lemmas  \\\n",
       "0  [beat, Dr., Dre, urbeat, Wired, Ear, Headphone...   \n",
       "1  [@Papapishu, man, fucking, rule, party, perpet...   \n",
       "2  [time, draw, close, 128591;&#127995, Father, d...   \n",
       "3  [notice, start, act, different, distant, peep,...   \n",
       "4  [forget, unfollower, believe, grow, new, follo...   \n",
       "\n",
       "                                           md_lemmas  \\\n",
       "0  [beat, Dr., Dre, urbeat, Wired, ear, Headphone...   \n",
       "1  [@Papapishu, man, fucking, rule, party, perpet...   \n",
       "2  [time, draw, close, 128591;&#127995, Father, d...   \n",
       "3  [notice, start, act, different, distant, peep,...   \n",
       "4  [forget, unfollower, believe, grow, new, follo...   \n",
       "\n",
       "                                           lg_lemmas  inappropriate  \n",
       "0  [beat, Dr., Dre, urBeats, wire, Ear, Headphone...           True  \n",
       "1  [@Papapishu, man, fucking, rule, party, perpet...           True  \n",
       "2  [time, draw, close, 128591;&#127995, Father, d...          False  \n",
       "3  [notice, start, act, different, distant, peep,...          False  \n",
       "4  [forget, unfollower, believe, grow, new, follo...          False  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "medium_lemmas = lemmas[[\"md_lemmas\", \"inappropriate\"]].copy()\n",
    "del lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(medium_lemmas, test_size=.2, random_state=42)\n",
    "train, val = train_test_split(train, test_size=.15, random_state=42)\n",
    "target = 'inappropriate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "y_train = train[target]\n",
    "y_val = val[target]\n",
    "\n",
    "x_train = train.drop([target], axis=1)\n",
    "x_val = val.drop([target], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We look to get each lemma in our file (up to a maximum number of features) coded to an integer so we can pass these tweets into an embedding layer. Since preprocessing was done in the lemmatization step, we create a CountVectorizer -- whose attributes we will access to create our vocab -- but turn off all of its automatic text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def do_nothing(tokens):\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=do_nothing, preprocessor=None, lowercase=False, stop_words=\"english\", max_features=5000, min_df=.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=False, max_df=1.0, max_features=5000, min_df=0.0001,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<function do_nothing at 0x0000028736EF8948>,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(x_train[\"md_lemmas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "word2idx = {word: idx for idx, word in enumerate(vectorizer.get_feature_names())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "word2idx[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def to_sequence(index, text):\n",
    "    indexes = [index[word] for word in text if word in index]\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x_train[\"integers\"] = x_train[\"md_lemmas\"].apply(lambda x: to_sequence(word2idx, x))\n",
    "x_val[\"integers\"] = x_val[\"md_lemmas\"].apply(lambda x: to_sequence(word2idx, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>md_lemmas</th>\n",
       "      <th>integers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14520</th>\n",
       "      <td>[.@pepsi, think, protest, hip, cute, thing, mi...</td>\n",
       "      <td>[4580, 3824, 2838, 2077, 4579, 3360, 3843, 2931]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68713</th>\n",
       "      <td>[Mississauga, load, line, finally, click, Spen...</td>\n",
       "      <td>[3221, 3199, 2539, 1851, 3212, 4612, 1531]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117901</th>\n",
       "      <td>[kejriwal, accept, role, making, udtapunjab, c...</td>\n",
       "      <td>[1258, 4043, 3283, 4721, 1955, 3838]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61528</th>\n",
       "      <td>[@AsEasyAsRiding, @lastnotlost, @shoestringcyc...</td>\n",
       "      <td>[3193]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115752</th>\n",
       "      <td>[time, like, boxer, rapper, etc, bitch, fuckin...</td>\n",
       "      <td>[4608, 3193, 3888, 1578, 2632, 2805, 1781, 355...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                md_lemmas  \\\n",
       "14520   [.@pepsi, think, protest, hip, cute, thing, mi...   \n",
       "68713   [Mississauga, load, line, finally, click, Spen...   \n",
       "117901  [kejriwal, accept, role, making, udtapunjab, c...   \n",
       "61528   [@AsEasyAsRiding, @lastnotlost, @shoestringcyc...   \n",
       "115752  [time, like, boxer, rapper, etc, bitch, fuckin...   \n",
       "\n",
       "                                                 integers  \n",
       "14520    [4580, 3824, 2838, 2077, 4579, 3360, 3843, 2931]  \n",
       "68713          [3221, 3199, 2539, 1851, 3212, 4612, 1531]  \n",
       "117901               [1258, 4043, 3283, 4721, 1955, 3838]  \n",
       "61528                                              [3193]  \n",
       "115752  [4608, 3193, 3888, 1578, 2632, 2805, 1781, 355...  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "As reviews are likely to be longer than tweets, we increase our max sequence length to allow our model to process texts of longer length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length = (max(x_train[\"integers\"].apply(lambda x: len(x))) * 2)\n",
    "max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "n_features = len(vectorizer.get_feature_names())\n",
    "x_train_sequences = pad_sequences(x_train[\"integers\"], maxlen = max_seq_length, value=n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x_val_sequences = pad_sequences(x_val[\"integers\"], maxlen=max_seq_length, value=n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "       5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000,\n",
       "       4580, 3824, 2838, 2077, 4579, 3360, 3843, 2931])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 30, 64)            320064    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 353,153\n",
      "Trainable params: 353,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(vectorizer.get_feature_names()) + 1,\n",
    "                    64,\n",
    "                    input_length=max_seq_length))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    " \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23/runs/2y4owje3\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23/runs/2y4owje3</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "wandb: Wandb version 0.8.35 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99459 samples\n",
      "Epoch 1/3\n",
      "99459/99459 [==============================] - 75s 759us/sample - loss: 0.3463 - accuracy: 0.8545\n",
      "Epoch 2/3\n",
      "99459/99459 [==============================] - 69s 697us/sample - loss: 0.3067 - accuracy: 0.8713\n",
      "Epoch 3/3\n",
      "99459/99459 [==============================] - 60s 604us/sample - loss: 0.2832 - accuracy: 0.8793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run pip install nbformat to save notebook history\n"
     ]
    }
   ],
   "source": [
    "WANDB_NOTEBOOK_NAME = \"train_models.ipynb\"\n",
    "wandb.init(project=\"allay-ds-23\", config = {\"epochs\": 3, \"optimizer\": \"adam\", \"batch_size\": 20})\n",
    "results = model.fit(x_train_sequences,\n",
    "                    y_train,\n",
    "                    epochs=3,\n",
    "                   batch_size=20,\n",
    "                   callbacks=[WandbCallback(validation_data=(x_val_sequences, y_val),\n",
    "                labels=[\"appropriate\", \"inappropriate\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17552/17552 [==============================] - 1s 59us/sample\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False     0.8569    0.9119    0.8835     10223\n",
      "        True     0.8650    0.7876    0.8245      7329\n",
      "\n",
      "    accuracy                         0.8600     17552\n",
      "   macro avg     0.8609    0.8497    0.8540     17552\n",
      "weighted avg     0.8603    0.8600    0.8589     17552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val_sequences, batch_size=64, verbose=1)\n",
    "y_pred = np.round(y_pred)\n",
    "print(classification_report(y_val, y_pred, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allay-ds-cRyEcJS9",
   "language": "python",
   "name": "allay-ds-cryecjs9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
