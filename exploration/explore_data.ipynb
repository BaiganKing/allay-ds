{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Traditional job sites can be overwhelming. Additionally, Lambda School graduates can save time and anxiety by focusing on companies who understand the unique value Lambda graduates bring as employees. Therefore we are developing a website where Lambda School students and alumni can post company and interview experiences and find helpful posts that others have made. \n",
    "\n",
    "For its first user feature, the Data Science team is developing automated content moderation. As the website scales, manual content moderation may not be a pragmatic way of enforcing content rules. Furthermore, inappropriate content undermines the site's core mission of saving Lambda students time and helping ease their anxieties. Therefore we seek to find a model that can automatically and accurately classify posts that should be flagged or removed.\n",
    "\n",
    "It is worth noting that many tweets in the data used within this notebook contain hateful or obscene content. Those who may be traumatized by such content may want to avoid reading this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Modeling Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "At the risk of tautology, data science requires data. So we first assess the data we have available and what we can get. We face a classic problem right now in building out features for a fledgling site: because we don't have users, we don't have actual user data; however, we'll never generate enough users to have sufficient data if they're encountering abusive and hateful content. For this reason, we concluded starting with a model trained on external data was a possible route.\n",
    "\n",
    "We were able to find several labeled data sets that flagged hateful, abusive, or spam content (or some combination of the three). Our initial strategy will be to use these to train, validate, and test models. It is worth noting that all three data sets were composed of Tweets. Our hope is that patterns of abusive text are similar enough across websites that the model learning on this will transfer.\n",
    "\n",
    "We will load and explore the data, then fit sequentially more complex models in order to maximize predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from wandb.keras import WandbCallback\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hundred_k_tweets = pd.read_csv(\"data\\\\hatespeech_text_label_vote.csv\", sep='\\t', header=None, names=[\"tweet\", \"category\", \"votes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hundred_k_tweets[\"inappropriate\"] = (hundred_k_tweets[\"category\"].isin([\"spam\", \"abusive\", \"hateful\"]))\n",
    "hundred_k_tweets = hundred_k_tweets.drop([\"category\", \"votes\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "additional_tweets = pd.read_csv(\"data\\\\labeled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "additional_tweets = additional_tweets.drop([\"Unnamed: 0\"], axis=1)\n",
    "additional_tweets[\"inappropriate\"] = additional_tweets[\"class\"] != 2\n",
    "additional_tweets = additional_tweets.drop([\"count\", \"hate_speech\", \"offensive_language\", \"neither\", \"class\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "kaggle_tweets = pd.read_csv(\"data/train_E6oV3lV.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "kaggle_tweets[\"inappropriate\"] = kaggle_tweets[\"label\"]\n",
    "kaggle_tweets = kaggle_tweets.drop([\"id\", \"label\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dfs = [hundred_k_tweets, additional_tweets, kaggle_tweets]\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['tweet', 'inappropriate'])\n",
    "appropriate = ~df['inappropriate']\n",
    "dupe_tweet = df.duplicated(subset=['tweet'], keep=False)\n",
    "df = df[~((dupe_tweet) & (appropriate))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146264, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated(subset=['tweet']).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# df.to_csv('combined_deduped.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allay-ds-cRyEcJS9",
   "language": "python",
   "name": "allay-ds-cryecjs9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
