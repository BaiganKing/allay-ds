{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Train Hate Speech Recognition Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "With the data cleaned and processed, this notebook implements model training on the data sets. The code in this notebook assumes that cleaned data is in the filepath `\"data/combined_deduped.csv\"`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_fscore_support, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from tensorflow import keras\n",
    "from wandb.keras import WandbCallback\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We'll start by fitting basic models with default parameters. As machine learning models and neural networks have many hyperparameters that can be tweaked, these will serve as a baseline: combinations of hyperparameter settings that improve the model from this baseline should be investigated, while those that degrade model performance should be seen as less promising.\n",
    "\n",
    "As modeling is an iterative process, we start by establishing some functions to automate the repetitive aspects of establishing baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def reset_data_with_val():\n",
    "    \"\"\"\n",
    "    Loads data, returns training and validation data\"\"\"\n",
    "    tweets = pd.read_csv(\"data/combined_deduped.csv\")\n",
    "    train, test = train_test_split(tweets, test_size = .2, random_state=42)\n",
    "    train, val = train_test_split(train, test_size = .15, random_state = 42)\n",
    "    x_train, y_train, x_val, y_val = train[\"tweet\"], train[\"inappropriate\"], val[\"tweet\"], val[\"inappropriate\"]\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def baseline_model(vect, clf, x_train, y_train, x_val, y_val, scaling=False):\n",
    "    \"\"\"Takes a text vectorizer, a classification model, and \n",
    "    data and outputs that model's score on the data.\n",
    "    \n",
    "    Sub-arguments can be passed to the arguments in the function: \n",
    "    for example, passing `vect = CountVectorizer(stop_words='english')`.\n",
    "    However, as this function doesn't return a fitted model, just model\n",
    "    scores, it is primarily intended to quickly test many basic \n",
    "    model archetypes.\n",
    "\n",
    "    Arguments:\n",
    "        vect {vectorizer} -- e.g. CountVectorizer(), TfidfVectorizer()\n",
    "        clf {classifier} -- eg RandomForest(), MultinomialNB()\n",
    "        x_train {array} -- features and values of the training set\n",
    "        y_train {1d array} -- target values for the training set\n",
    "        x_val {array} -- features and values of the validation set\n",
    "        y_val {1d array} -- target values for the validation set\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        scaling {bool} -- scale data if required by model (default: {False})\n",
    "    \n",
    "    Returns:\n",
    "        accuracy, precision, recall, f1, roc_auc -- metrics of model performance\n",
    "    \"\"\"\n",
    "    x_train = vect.fit_transform(x_train)\n",
    "    x_val = vect.transform(x_val)\n",
    "    \n",
    "    if scaling == True:\n",
    "        scaler = StandardScaler(with_mean=False)\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_val = scaler.fit_transform(x_val)\n",
    "        \n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_val)\n",
    "    \n",
    "    accuracy = clf.score(x_val, y_val)\n",
    "    precision, recall, f1, other = precision_recall_fscore_support(y_val, \n",
    "                                                                   y_pred, \n",
    "                                                                   average='binary')\n",
    "    roc_auc = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "    return accuracy, precision, recall, f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def report_to_wandb(accuracy, precision, recall, f1, roc_auc):\n",
    "    \"\"\"Reports a dictionary summarizing model performance\n",
    "    to the \"Weights and Biases\" app associated with this project.\n",
    "    \n",
    "    Arguments:\n",
    "        accuracy {float} -- [description]\n",
    "        precision {float} -- [description]\n",
    "        recall {float} -- [description]\n",
    "        f1 {float} -- [description]\n",
    "        roc_auc {float} -- [description]\n",
    "    \"\"\"\n",
    "    wandb.log({'accuracy':accuracy, 'recall':recall, \n",
    "               'f1':f1, 'precision':precision, \n",
    "               'roc_auc_score':roc_auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val = reset_data_with_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def implement_training(vect, clf, \n",
    "    x_train=x_train, y_train=y_train, \n",
    "    x_val=x_val, y_val=y_val):\n",
    "    \"\"\"This function initializes a weights and biases run, then calls the \n",
    "    helper functions in order to perform a full cycle of model training.\n",
    "\n",
    "    Note that attempting to define this function before x_train, y_train, \n",
    "    x_val, and y_val are assigned local variables will generate an error, as \n",
    "    they're called as the default arguments. These have been set as default\n",
    "    arguments for convenience when fitting multiple models. \n",
    "    \n",
    "    Arguments:\n",
    "        vect {Vectorizer} -- sklearn-compatible text vectorizer\n",
    "        clf {Classifier} -- sklearn-compatible classification model\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        x_train {array} -- training features/values (default: {x_train})\n",
    "        y_train {1d array} -- training target values (default: {y_train})\n",
    "        x_val {array} -- validation features/values (default: {x_val})\n",
    "        y_val {1d array} -- validation target values (default: {y_val})\n",
    "    \"\"\"\n",
    "    wandb.init(project=\"allay-ds-23\")\n",
    "    accuracy, precision, recall, f1, roc_auc = baseline_model(vect, clf, \n",
    "                                        x_train, y_train, \n",
    "                                        x_val, y_val)\n",
    "    report_to_wandb(accuracy, precision, recall, f1, roc_auc)\n",
    "\n",
    "    return(\"Accuracy:\", accuracy, \"Precision:\", precision,\n",
    "        \"Recall:\", recall, \"F1:\", f1, \"ROC_AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Baseline ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Majority Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.582441\n",
       "True     0.417559\n",
       "Name: inappropriate, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False     0.5824    1.0000    0.7361     10223\n",
      "        True     0.0000    0.0000    0.0000      7329\n",
      "\n",
      "    accuracy                         0.5824     17552\n",
      "   macro avg     0.2912    0.5000    0.3681     17552\n",
      "weighted avg     0.3392    0.5824    0.4288     17552\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajenk\\.virtualenvs\\allay-ds-cRyEcJS9\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = y_val * 0\n",
    "print(classification_report(y_val, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23/runs/3iw8dreb\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23/runs/3iw8dreb</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajenk\\.virtualenvs\\allay-ds-cRyEcJS9\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Accuracy:',\n",
       " 0.8650296262534184,\n",
       " 'Precision:',\n",
       " 0.8802514566084023,\n",
       " 'Recall:',\n",
       " 0.7833265111202073,\n",
       " 'F1:',\n",
       " 0.8289654176593747,\n",
       " 'ROC_AUC:',\n",
       " 0.8534650749868863)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implement_training(vect, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.863320419325433,\n",
       " 0.8849156777014366,\n",
       " 0.7732296356938191,\n",
       " 0.8253112939634457,\n",
       " 0.8505686474468312)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model(vect, clf, x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23/runs/3mcw46pj\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23/runs/3mcw46pj</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Accuracy:',\n",
       " 0.863320419325433,\n",
       " '/nPrecision:',\n",
       " 0.8849156777014366,\n",
       " '/nRecall:',\n",
       " 0.7732296356938191,\n",
       " '/nF1:',\n",
       " 0.8253112939634457,\n",
       " '/nROC_AUC:',\n",
       " 0.8505686474468312)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implement_training(vect, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23/runs/2zh784do\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23/runs/2zh784do</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Accuracy:',\n",
       " 0.8469690063810392,\n",
       " 'Precision:',\n",
       " 0.8710244526130734,\n",
       " 'Recall:',\n",
       " 0.743621230727248,\n",
       " 'F1:',\n",
       " 0.8022964816723098,\n",
       " 'ROC_AUC:',\n",
       " 0.8323407924153701)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implement_training(vect, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23/runs/37af9rkz\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23/runs/37af9rkz</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Accuracy:',\n",
       " 0.8229831358249772,\n",
       " 'Precision:',\n",
       " 0.9211891460494812,\n",
       " 'Recall:',\n",
       " 0.6299631600491199,\n",
       " 'F1:',\n",
       " 0.7482375820435944,\n",
       " 'ROC_AUC:',\n",
       " 0.7956623977884257)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = TfidfVectorizer()\n",
    "implement_training(vect, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23/runs/1myixgfe\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23/runs/1myixgfe</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajenk\\.virtualenvs\\allay-ds-cRyEcJS9\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Accuracy:',\n",
       " 0.8507292616226071,\n",
       " 'Precision:',\n",
       " 0.8453865336658354,\n",
       " 'Recall:',\n",
       " 0.7863282848956201,\n",
       " 'F1:',\n",
       " 0.8147886328290682,\n",
       " 'ROC_AUC:',\n",
       " 0.8416137169367077)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implement_training(vect, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23/runs/6j5wh8mg\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23/runs/6j5wh8mg</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Accuracy:',\n",
       " 0.8605287146763901,\n",
       " 'Precision:',\n",
       " 0.8562253685593344,\n",
       " 'Recall:',\n",
       " 0.8003820439350525,\n",
       " 'F1:',\n",
       " 0.8273624823695346,\n",
       " 'ROC_AUC:',\n",
       " 0.8520153396824827)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implement_training(vect, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23/runs/3w229j0j\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23/runs/3w229j0j</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Accuracy:',\n",
       " 0.8521536007292616,\n",
       " 'Precision:',\n",
       " 0.9043389135633755,\n",
       " 'Recall:',\n",
       " 0.7223359257743212,\n",
       " 'F1:',\n",
       " 0.8031555791549723,\n",
       " 'ROC_AUC:',\n",
       " 0.8337787425017551)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implement_training(vect, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23/runs/189vdpvm\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23/runs/189vdpvm</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Accuracy:',\n",
       " 0.8327825888787602,\n",
       " 'Precision:',\n",
       " 0.8206363105662581,\n",
       " 'Recall:',\n",
       " 0.7672260881429935,\n",
       " 'F1:',\n",
       " 0.7930329313870671,\n",
       " 'ROC_AUC:',\n",
       " 0.8235034871899551)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implement_training(vect, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Gradient-Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23/runs/2niyxkx4\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23/runs/2niyxkx4</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Accuracy:',\n",
       " 0.8648587055606198,\n",
       " 'Precision:',\n",
       " 0.9335315725030611,\n",
       " 'Recall:',\n",
       " 0.7282030290626279,\n",
       " 'F1:',\n",
       " 0.8181818181818182,\n",
       " 'ROC_AUC:',\n",
       " 0.8455159721269317)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implement_training(vect, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/alexmjn/allay-ds-23/runs/3el65qwi\" target=\"_blank\">https://app.wandb.ai/alexmjn/allay-ds-23/runs/3el65qwi</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Accuracy:',\n",
       " 0.85859161349134,\n",
       " 'Precision:',\n",
       " 0.9106931028639214,\n",
       " 'Recall:',\n",
       " 0.7332514667758221,\n",
       " 'F1:',\n",
       " 0.8123960695389266,\n",
       " 'ROC_AUC:',\n",
       " 0.8408505206323598)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implement_training(vect, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Neural Network Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The \"baseline\" implementation of a neural network is more debatable. Our choice was to set up a simple multilayer perceptron with enough neurons and layers to be functional and little customization beyond that. \n",
    "\n",
    "The text vectorization methods used for baseline modeling generate a sparse matrix of word appearances. This needs to be converted into a dense array for our Keras model to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words = 'english', max_features=3000)\n",
    "x_train_vect = vect.fit_transform(x_train)\n",
    "x_val_vect = vect.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean = False)\n",
    "x_train_vect_scale = scaler.fit_transform(x_train_vect)\n",
    "x_val_vect_scale = scaler.transform(x_val_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x_train_vect_scale = x_train_vect_scale.toarray()\n",
    "x_val_vect_scale = x_val_vect_scale.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, input_dim=3000, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99459 samples\n",
      "Epoch 1/5\n",
      "99459/99459 [==============================] - 24s 242us/sample - loss: 0.3936 - accuracy: 0.8339\n",
      "Epoch 2/5\n",
      "99459/99459 [==============================] - 21s 216us/sample - loss: 0.3044 - accuracy: 0.8750\n",
      "Epoch 3/5\n",
      "99459/99459 [==============================] - 27s 269us/sample - loss: 0.2521 - accuracy: 0.8968\n",
      "Epoch 4/5\n",
      "99459/99459 [==============================] - 20s 203us/sample - loss: 0.1917 - accuracy: 0.9237\n",
      "Epoch 5/5\n",
      "99459/99459 [==============================] - 20s 204us/sample - loss: 0.1391 - accuracy: 0.9467\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(x_train_vect_scale,\n",
    "                    y_train,\n",
    "                    epochs=5,\n",
    "                   batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17552/17552 [==============================] - 2s 115us/sample - loss: 0.5089 - accuracy: 0.8394\n",
      "17552/17552 [==============================] - 1s 59us/sample\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_val_vect_scale, y_val)\n",
    "y_pred = model.predict(x_val_vect_scale, batch_size=64, verbose=1)\n",
    "y_pred = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False     0.8487    0.8813    0.8647     10223\n",
      "        True     0.8251    0.7809    0.8024      7329\n",
      "\n",
      "    accuracy                         0.8394     17552\n",
      "   macro avg     0.8369    0.8311    0.8336     17552\n",
      "weighted avg     0.8389    0.8394    0.8387     17552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words = 'english', max_features=3000)\n",
    "x_train_vect = vect.fit_transform(x_train)\n",
    "x_val_vect = vect.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "x_train_vect = x_train_vect.toarray()\n",
    "x_val_vect = x_val_vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, input_dim=3000, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99459 samples\n",
      "Epoch 1/5\n",
      "99459/99459 [==============================] - 21s 210us/sample - loss: 0.3494 - accuracy: 0.8495\n",
      "Epoch 2/5\n",
      "99459/99459 [==============================] - 20s 204us/sample - loss: 0.2990 - accuracy: 0.8754\n",
      "Epoch 3/5\n",
      "99459/99459 [==============================] - 20s 202us/sample - loss: 0.2620 - accuracy: 0.8918\n",
      "Epoch 4/5\n",
      "99459/99459 [==============================] - 20s 202us/sample - loss: 0.2114 - accuracy: 0.9140\n",
      "Epoch 5/5\n",
      "99459/99459 [==============================] - 21s 209us/sample - loss: 0.1557 - accuracy: 0.9380\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(x_train_vect,\n",
    "                    y_train,\n",
    "                    epochs=5,\n",
    "                   batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17552/17552 [==============================] - 1s 51us/sample\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False     0.8608    0.8945    0.8773     10223\n",
      "        True     0.8443    0.7982    0.8206      7329\n",
      "\n",
      "    accuracy                         0.8543     17552\n",
      "   macro avg     0.8525    0.8463    0.8489     17552\n",
      "weighted avg     0.8539    0.8543    0.8536     17552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val_vect, batch_size=64, verbose=1)\n",
    "y_pred = np.round(y_pred)\n",
    "print(classification_report(y_val, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# ML Models: Hyperparameter Tuning and Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Gradient-Boosted Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## NNs: Hyperparameter Tuning and Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allay-ds-cRyEcJS9",
   "language": "python",
   "name": "allay-ds-cryecjs9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
